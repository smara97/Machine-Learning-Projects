{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-LM.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smara97/Machine-Learning-Projects/blob/master/Generate%20Text%20Language%20Model%20/RNN_LM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDM1ROHR-Cvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from io import open\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y60OVdyc_Z4T",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "3ff14a11-db60-4819-9a1b-23d6fe6a3663"
      },
      "source": [
        "up=files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7a581505-62f7-422d-85d4-bf591c4cb647\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7a581505-62f7-422d-85d4-bf591c4cb647\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving anna.txt to anna.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGNsbK7v-Rzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines=[]\n",
        "with open (\"/content/anna.txt\",'r',encoding=\"utf8\") as f:\n",
        "    lines=f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEjr0v3H-R2p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8a75a48f-bac6-4155-9646-c93b64361b07"
      },
      "source": [
        "chars=tuple(set(lines))\n",
        "print(chars)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('p', 's', '_', 'j', ';', '*', 'x', 'm', 'k', 'D', '$', 'n', '/', 'O', 'P', '2', 'X', 'q', 'e', ':', '.', \"'\", ' ', 'H', 'I', '(', '-', '@', '7', 'Y', 'K', '?', 'A', '4', 'u', '3', 'R', 'V', 'h', 'r', 'y', 'a', '1', '\"', 'J', 'o', ')', 'L', 'g', 'f', 'w', 't', 'c', 'Q', '&', 'v', 'M', 'z', '8', 'd', '0', 'U', '9', '`', ',', 'b', 'i', '!', 'G', 'Z', '6', '%', '5', 'l', 'E', 'B', 'T', 'S', 'F', '\\n', 'W', 'C', 'N')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDm8kpWP-R5g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "38a872f6-f0ae-4e9b-8990-ae137d2a7670"
      },
      "source": [
        "int2char=dict(enumerate(chars))\n",
        "char2int={ch:ii for ii,ch in int2char.items()}\n",
        "print(int2char)\n",
        "print(char2int)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'p', 1: 's', 2: '_', 3: 'j', 4: ';', 5: '*', 6: 'x', 7: 'm', 8: 'k', 9: 'D', 10: '$', 11: 'n', 12: '/', 13: 'O', 14: 'P', 15: '2', 16: 'X', 17: 'q', 18: 'e', 19: ':', 20: '.', 21: \"'\", 22: ' ', 23: 'H', 24: 'I', 25: '(', 26: '-', 27: '@', 28: '7', 29: 'Y', 30: 'K', 31: '?', 32: 'A', 33: '4', 34: 'u', 35: '3', 36: 'R', 37: 'V', 38: 'h', 39: 'r', 40: 'y', 41: 'a', 42: '1', 43: '\"', 44: 'J', 45: 'o', 46: ')', 47: 'L', 48: 'g', 49: 'f', 50: 'w', 51: 't', 52: 'c', 53: 'Q', 54: '&', 55: 'v', 56: 'M', 57: 'z', 58: '8', 59: 'd', 60: '0', 61: 'U', 62: '9', 63: '`', 64: ',', 65: 'b', 66: 'i', 67: '!', 68: 'G', 69: 'Z', 70: '6', 71: '%', 72: '5', 73: 'l', 74: 'E', 75: 'B', 76: 'T', 77: 'S', 78: 'F', 79: '\\n', 80: 'W', 81: 'C', 82: 'N'}\n",
            "{'p': 0, 's': 1, '_': 2, 'j': 3, ';': 4, '*': 5, 'x': 6, 'm': 7, 'k': 8, 'D': 9, '$': 10, 'n': 11, '/': 12, 'O': 13, 'P': 14, '2': 15, 'X': 16, 'q': 17, 'e': 18, ':': 19, '.': 20, \"'\": 21, ' ': 22, 'H': 23, 'I': 24, '(': 25, '-': 26, '@': 27, '7': 28, 'Y': 29, 'K': 30, '?': 31, 'A': 32, '4': 33, 'u': 34, '3': 35, 'R': 36, 'V': 37, 'h': 38, 'r': 39, 'y': 40, 'a': 41, '1': 42, '\"': 43, 'J': 44, 'o': 45, ')': 46, 'L': 47, 'g': 48, 'f': 49, 'w': 50, 't': 51, 'c': 52, 'Q': 53, '&': 54, 'v': 55, 'M': 56, 'z': 57, '8': 58, 'd': 59, '0': 60, 'U': 61, '9': 62, '`': 63, ',': 64, 'b': 65, 'i': 66, '!': 67, 'G': 68, 'Z': 69, '6': 70, '%': 71, '5': 72, 'l': 73, 'E': 74, 'B': 75, 'T': 76, 'S': 77, 'F': 78, '\\n': 79, 'W': 80, 'C': 81, 'N': 82}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDUzc5xR-R8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encode=np.array([char2int[ch] for ch in lines])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkweLCJp-R_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encode(arr,labels):\n",
        "    \n",
        "    one_hot=np.zeros((np.multiply(*arr.shape),labels),dtype=np.float32)\n",
        "    one_hot[np.arange(one_hot.shape[0]),arr.flatten()]=1\n",
        "    one_hot=one_hot.reshape((*arr.shape,labels))\n",
        "    \n",
        "    return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvmY1X6x-SCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(arr, batch_size, seq_length):\n",
        "\n",
        "    batch_size_total = batch_size * seq_length\n",
        "\n",
        "    n_batches = len(arr)//batch_size_total\n",
        "    \n",
        "    arr = arr[:n_batches * batch_size_total]\n",
        "    \n",
        "    arr = arr.reshape((batch_size, -1))\n",
        "    \n",
        "    for n in range(0, arr.shape[1], seq_length):\n",
        "        x = arr[:, n:n+seq_length]\n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
        "        except IndexError:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "        yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqkgy2bi-SFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self,tokens,n_hidden=265,n_layers=2,drop_prop=0.5,lr=0.001):\n",
        "        super().__init__()\n",
        "        self.drop_prop=drop_prop\n",
        "        self.lr=lr\n",
        "        self.n_layers=n_layers\n",
        "        self.n_hidden=n_hidden\n",
        "        \n",
        "        self.chars=tokens\n",
        "        self.int2char=dict(enumerate(self.chars))\n",
        "        self.char2int={ch:ii for ii,ch in self.int2char.items()}\n",
        "        \n",
        "        self.lstm=nn.LSTM(len(self.chars),n_hidden,n_layers,dropout=drop_prop,batch_first=True)\n",
        "        self.dropout=nn.Dropout(drop_prop)\n",
        "        self.fc=nn.Linear(n_hidden,len(chars))\n",
        "        \n",
        "    def forward(self,x,hidden):\n",
        "        r_output,hidden=self.lstm(x,hidden)\n",
        "        out=self.dropout(r_output)\n",
        "        out=out.contiguous().view(-1,self.n_hidden)\n",
        "        out=self.fc(out)\n",
        "        \n",
        "        return out,hidden\n",
        "    \n",
        "    def init_hidden(self,batch_size):\n",
        "        weight=next(self.parameters()).data.cuda()\n",
        "        hidden=(weight.new(self.n_layers,batch_size,self.n_hidden).zero_().cuda(),\n",
        "                weight.new(self.n_layers,batch_size,self.n_hidden).zero_().cuda())\n",
        "        \n",
        "        \n",
        "        return hidden\n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rFltvps-SIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "24321f99-e425-4b74-f92b-bc9129bfd264"
      },
      "source": [
        "net=RNN(chars,512,2)\n",
        "net.cuda()\n",
        "print(net)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (lstm): LSTM(83, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=83, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP7reasP-SLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
        "    \n",
        "    net.train()\n",
        "    opt=torch.optim.Adam(net.parameters(),lr=lr)\n",
        "    crit=nn.CrossEntropyLoss()\n",
        "    val_idx = int(len(data)*(1-val_frac))\n",
        "    data, val_data = data[:val_idx], data[val_idx:]\n",
        "    \n",
        "    counter=0\n",
        "    n_chars=len(net.chars)\n",
        "    for e in range(epochs):\n",
        "        \n",
        "        h=net.init_hidden(batch_size)\n",
        "        \n",
        "        for x,y in get_batches(data,batch_size,seq_length):\n",
        "            counter+=1\n",
        "        \n",
        "            x=one_hot_encode(x,n_chars)\n",
        "            inputs,targets=torch.from_numpy(x),torch.from_numpy(y)\n",
        "            inputs,targets=inputs.cuda(),targets.cuda()\n",
        "            h=tuple([each.data for each in h])\n",
        "            \n",
        "            net.zero_grad()\n",
        "            out,h=net(inputs,h)\n",
        "            \n",
        "            loss=crit(out,targets.view(batch_size*seq_length).long())\n",
        "            loss.backward()\n",
        "            \n",
        "            nn.utils.clip_grad_norm(net.parameters(),clip)\n",
        "            opt.step()\n",
        "        val_h=net.init_hidden(batch_size)\n",
        "        val_losses=[]\n",
        "        net.eval()\n",
        "                \n",
        "        for x,y in get_batches(val_data,batch_size,seq_length):\n",
        "          \n",
        "          \n",
        "          x=one_hot_encode(x,n_chars)\n",
        "                    \n",
        "          x,y=torch.from_numpy(x),torch.from_numpy(y)\n",
        "          \n",
        "                    \n",
        "          val_h=tuple([each.data for each in val_h])\n",
        "          inputs,targets=x,y\n",
        "          inputs,targets=inputs.cuda(),targets.cuda()\n",
        "          out,val_h=net(inputs,val_h)\n",
        "          val_loss=crit(out,targets.view(batch_size*seq_length).long())\n",
        "          val_losses.append(val_loss.item())\n",
        "          net.train()\n",
        "                \n",
        "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "              \"Loss: {:.4f}...\".format(loss.item()),\n",
        "              \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
        "                \n",
        "                    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zavjorzP-SOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "8bfbe3d8-ba29-4268-b596-03a296aa14af"
      },
      "source": [
        "batch_size = 128\n",
        "seq_length = 100\n",
        "n_epochs = 20 \n",
        "train(net, encode, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
        "model_name = 'rnn_20_epoch.net'\n",
        "\n",
        "checkpoint = {'n_hidden': net.n_hidden,\n",
        "              'n_layers': net.n_layers,\n",
        "              'state_dict': net.state_dict(),\n",
        "              'tokens': net.chars}\n",
        "\n",
        "with open(model_name, 'wb') as f:\n",
        "  torch.save(checkpoint, f)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/20... Loss: 2.8070... Val Loss: 2.8055\n",
            "Epoch: 2/20... Loss: 2.2652... Val Loss: 2.3013\n",
            "Epoch: 3/20... Loss: 2.0332... Val Loss: 2.0726\n",
            "Epoch: 4/20... Loss: 1.8653... Val Loss: 1.9232\n",
            "Epoch: 5/20... Loss: 1.7516... Val Loss: 1.8095\n",
            "Epoch: 6/20... Loss: 1.6593... Val Loss: 1.7383\n",
            "Epoch: 7/20... Loss: 1.5960... Val Loss: 1.6782\n",
            "Epoch: 8/20... Loss: 1.5573... Val Loss: 1.6320\n",
            "Epoch: 9/20... Loss: 1.5091... Val Loss: 1.5921\n",
            "Epoch: 10/20... Loss: 1.4698... Val Loss: 1.5576\n",
            "Epoch: 11/20... Loss: 1.4395... Val Loss: 1.5378\n",
            "Epoch: 12/20... Loss: 1.4128... Val Loss: 1.5144\n",
            "Epoch: 13/20... Loss: 1.3969... Val Loss: 1.4948\n",
            "Epoch: 14/20... Loss: 1.3724... Val Loss: 1.4775\n",
            "Epoch: 15/20... Loss: 1.3556... Val Loss: 1.4619\n",
            "Epoch: 16/20... Loss: 1.3299... Val Loss: 1.4525\n",
            "Epoch: 17/20... Loss: 1.3257... Val Loss: 1.4444\n",
            "Epoch: 18/20... Loss: 1.3147... Val Loss: 1.4346\n",
            "Epoch: 19/20... Loss: 1.3033... Val Loss: 1.4253\n",
            "Epoch: 20/20... Loss: 1.2934... Val Loss: 1.4134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WATDmxRw-SQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(net ,char,h=None,top_k=None):\n",
        "  \n",
        "  x = np.array([[net.char2int[char]]])\n",
        "  x = one_hot_encode(x, len(net.chars))\n",
        "  inputs=torch.from_numpy(x).cuda()\n",
        "  \n",
        "  h=tuple([each.data for each in h])\n",
        "  out,h=net(inputs,h)\n",
        "  \n",
        "  p=F.softmax(out,dim=1).data\n",
        "  \n",
        "  p=p.cpu()\n",
        "  \n",
        "  if top_k is None:\n",
        "    top_ch = np.arange(len(net.chars))\n",
        "  else:\n",
        "    p, top_ch = p.topk(top_k)\n",
        "    top_ch = top_ch.numpy().squeeze()    \n",
        "  p = p.numpy().squeeze()\n",
        "  char = np.random.choice(top_ch, p=p/p.sum())\n",
        "  return net.int2char[char],h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7QqVmp_Fq3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(net, size, prime='The', top_k=None):\n",
        "  \n",
        "        \n",
        "  net.cuda()\n",
        "    \n",
        "  net.eval() \n",
        "\n",
        "  chars = [ch for ch in prime]\n",
        "  h = net.init_hidden(1)\n",
        "  for ch in prime:\n",
        "    char, h = predict(net, ch, h, top_k=top_k)\n",
        "  chars.append(char)\n",
        "    \n",
        "  for ii in range(size):\n",
        "    char, h = predict(net, chars[-1], h, top_k=top_k)\n",
        "    chars.append(char)\n",
        "\n",
        "  return ''.join(chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kWpWYEHF50i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "d24167cc-dbf2-4eb5-ce95-15db00a4f2b6"
      },
      "source": [
        "print(sample(net, 1000, prime='Ahmed', top_k=5))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ahmed the\n",
            "face in the\n",
            "courcity of his face to tell them\n",
            "in them.\n",
            "\n",
            "The strong\n",
            "study and the papard hands, a capital ask and southing of the\n",
            "children. This was not still at once to go to his foreer. Seeing that\n",
            "there was to saw it. She saw her. And all that had already to be sole to the position. Anna had always talked to him in a setter\n",
            "of man, and an annoyances he could\n",
            "nater her secretary. She did\n",
            "not be dispuce, the same\n",
            "time as they were some sister than ever as it herself went into her arm and took the parts of\n",
            "souldence, and\n",
            "to the motion, he saw.\n",
            "\n",
            "\"You don't stret the letter.\"\n",
            "\n",
            "\"Ah!\" said Levin, with silent as the marsh. And answered the marshal with his boy. He smoke with happiness, and without taking a people and then the mire as a pealit carm, so interrupted her for the\n",
            "pretemptoon and say with the carriage for this, almost all her hands the\n",
            "decones of the money of the strange had stopped his faculty, as\n",
            "she was streint to the carriage, and they\n",
            "saw him that, as though he carely an \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTFXxB2rF76h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}