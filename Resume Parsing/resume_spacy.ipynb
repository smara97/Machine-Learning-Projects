{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RENHMV9-We4f"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import plac \n",
    "import random\n",
    "import spacy\n",
    "import string\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyYt6EOOXBYd"
   },
   "outputs": [],
   "source": [
    "def mergeIntervals(intervals):\n",
    "    sorted_by_lower_bound = sorted(intervals, key=lambda tup: tup[0])\n",
    "    merged = []\n",
    "\n",
    "    for higher in sorted_by_lower_bound:\n",
    "        if not merged:\n",
    "            merged.append(higher)\n",
    "        else:\n",
    "            lower = merged[-1]\n",
    "            if higher[0] <= lower[1]:\n",
    "                if lower[2] is higher[2]:\n",
    "                    upper_bound = max(lower[1], higher[1])\n",
    "                    merged[-1] = (lower[0], upper_bound, lower[2])\n",
    "                else:\n",
    "                    if lower[1] > higher[1]:\n",
    "                        merged[-1] = lower\n",
    "                    else:\n",
    "                        merged[-1] = (lower[0], higher[1], higher[2])\n",
    "            else:\n",
    "                merged.append(higher)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02ntas3PWhxV"
   },
   "outputs": [],
   "source": [
    "def trim_entity_spans(data: list) -> list:\n",
    "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
    "\n",
    "    Args:\n",
    "        data (list): The data to be cleaned in spaCy JSON format.\n",
    "\n",
    "    Returns:\n",
    "        list: The cleaned data.\n",
    "    \"\"\"\n",
    "    invalid_span_tokens = re.compile(r'\\s')\n",
    "\n",
    "    cleaned_data = []\n",
    "    for text, annotations in data:\n",
    "        entities = annotations['entities']\n",
    "        valid_entities = []\n",
    "        for start, end, label in entities:\n",
    "            valid_start = start\n",
    "            valid_end = end\n",
    "            while valid_start < len(text) and invalid_span_tokens.match(\n",
    "                    text[valid_start]):\n",
    "                valid_start += 1\n",
    "            while valid_end > 1 and invalid_span_tokens.match(\n",
    "                    text[valid_end - 1]):\n",
    "                valid_end -= 1\n",
    "            valid_entities.append([valid_start, valid_end, label])\n",
    "        cleaned_data.append([text, {'entities': valid_entities}])\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
    "    try:\n",
    "        training_data = []\n",
    "        lines = []\n",
    "        with open(dataturks_JSON_FilePath, 'r', encoding=\"utf8\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            data = json.loads(line)\n",
    "            text = data['content']\n",
    "            entities = []\n",
    "            if data['annotation'] is not None:\n",
    "                for annotation in data['annotation']:\n",
    "                    point = annotation['points'][0]\n",
    "                    labels = annotation['label']\n",
    "                    if not isinstance(labels, list):\n",
    "                        labels = [labels]\n",
    "\n",
    "                    for label in labels:\n",
    "                        entities.append((\n",
    "                            point['start'],\n",
    "                            point['end'] + 1,\n",
    "                            label\n",
    "                        ))\n",
    "\n",
    "            training_data.append((text, {\"entities\": mergeIntervals(entities)}))\n",
    "        return training_data\n",
    "    except Exception:\n",
    "        logging.exception(\"Unable to process \" + dataturks_JSON_FilePath)\n",
    "        return None\n",
    "\n",
    "\n",
    "TRAIN_DATA = trim_entity_spans(convert_dataturks_to_spacy(\"/content/drive/My Drive/traindata.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "CJT81k9wXFhP",
    "outputId": "5e148b43-2968-47ab-8809-4ca42f6e2cee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Creating new pipe\n",
      "Iteration 0 Losses {'ner': 72881.84172887275}\n",
      "Iteration 1 Losses {'ner': 56274.57866312674}\n",
      "Iteration 2 Losses {'ner': 49364.31046622158}\n",
      "Iteration 3 Losses {'ner': 45600.37251938517}\n",
      "Iteration 4 Losses {'ner': 40238.84745400952}\n",
      "Iteration 5 Losses {'ner': 40765.96137773611}\n",
      "Iteration 6 Losses {'ner': 36079.835796331994}\n",
      "Iteration 7 Losses {'ner': 33979.621763201256}\n",
      "Iteration 8 Losses {'ner': 36937.14377678442}\n",
      "Iteration 9 Losses {'ner': 36304.54675359326}\n",
      "Iteration 10 Losses {'ner': 34965.55834843795}\n",
      "Iteration 11 Losses {'ner': 33993.4809869439}\n",
      "Iteration 12 Losses {'ner': 31454.66553217383}\n",
      "Iteration 13 Losses {'ner': 31362.75079856239}\n",
      "Iteration 14 Losses {'ner': 31617.293582180206}\n",
      "Iteration 15 Losses {'ner': 30012.023781760192}\n",
      "Iteration 16 Losses {'ner': 29134.73870886322}\n",
      "Iteration 17 Losses {'ner': 28835.70033996148}\n",
      "Iteration 18 Losses {'ner': 29160.606647147368}\n",
      "Iteration 19 Losses {'ner': 29578.627700421486}\n",
      "Iteration 20 Losses {'ner': 28788.532659379194}\n",
      "Iteration 21 Losses {'ner': 27064.337550711538}\n",
      "Iteration 22 Losses {'ner': 28084.02435709312}\n",
      "Iteration 23 Losses {'ner': 27878.75370534876}\n",
      "Iteration 24 Losses {'ner': 26401.552273980673}\n",
      "Iteration 25 Losses {'ner': 25317.5048766489}\n",
      "Iteration 26 Losses {'ner': 24889.425649461627}\n",
      "Iteration 27 Losses {'ner': 25720.748309938506}\n",
      "Iteration 28 Losses {'ner': 23664.128494793957}\n",
      "Iteration 29 Losses {'ner': 22669.417876139934}\n",
      "Iteration 30 Losses {'ner': 24081.13850464899}\n",
      "Iteration 31 Losses {'ner': 23577.05177086928}\n",
      "Iteration 32 Losses {'ner': 22586.097940851352}\n",
      "Iteration 33 Losses {'ner': 23564.741121863655}\n",
      "Iteration 34 Losses {'ner': 23241.507279959555}\n",
      "Iteration 35 Losses {'ner': 23210.70050864055}\n",
      "Iteration 36 Losses {'ner': 21950.176579226638}\n",
      "Iteration 37 Losses {'ner': 21553.085228007654}\n",
      "Iteration 38 Losses {'ner': 21833.072951453607}\n",
      "Iteration 39 Losses {'ner': 21719.881867845797}\n",
      "Iteration 40 Losses {'ner': 22021.231704614842}\n",
      "Iteration 41 Losses {'ner': 20764.460335193384}\n",
      "Iteration 42 Losses {'ner': 21757.421664910493}\n",
      "Iteration 43 Losses {'ner': 21325.853713988057}\n",
      "Iteration 44 Losses {'ner': 21590.240238939376}\n",
      "Iteration 45 Losses {'ner': 21441.485442083707}\n",
      "Iteration 46 Losses {'ner': 21424.991868044057}\n",
      "Iteration 47 Losses {'ner': 19827.715815369495}\n",
      "Iteration 48 Losses {'ner': 20746.84083292897}\n",
      "Iteration 49 Losses {'ner': 20913.60630721061}\n"
     ]
    }
   ],
   "source": [
    "model=None\n",
    "random.seed(0)\n",
    "if model is not None:\n",
    "    nlp = spacy.load(model) \n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "    nlp = spacy.blank(\"en\") \n",
    "    print(\"Created blank 'en' model\")\n",
    "\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    print(\"Creating new pipe\")\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "iters=60\n",
    "\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "  \n",
    "move_names = list(ner.move_names)\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(iters):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in TRAIN_DATA:\n",
    "            nlp.update(\n",
    "                [text], \n",
    "                [annotations],  \n",
    "                drop=0.4,  \n",
    "                 sgd=optimizer,  \n",
    "                losses=losses)\n",
    "        print(\"Iteration \" + str(itn),\"Losses\", losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3e3UnVvEvD53"
   },
   "outputs": [],
   "source": [
    "nlp.to_disk('/content/drive/My Drive/pyre_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wC-v2z82wkuz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "resume_spacy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
